{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from itertools import combinations\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/assignment_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2572, 55)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ['country_id','application_id','product_id','customer_id']\n",
    "dates = [\n",
    "    'due_date',\n",
    "    'first_status_day_date',\n",
    "    'first_status_time_of_day',\n",
    "    'paid_date',\n",
    "    'arrived_date',\n",
    "    'Variable_42',\n",
    "    'Variable_43',\n",
    "    'Variable_44']\n",
    "\n",
    "categoricals = ['Variable_5','Variable_6','Variable_12','Variable_45']\n",
    "\n",
    "ordinals = ['Variable_13','Variable_14']\n",
    "numericals = [\n",
    "    x for x in data.columns if \n",
    "    (x not in ids) and \n",
    "    (x not in dates) and \n",
    "    (x not in categoricals) and \n",
    "    (x not in ordinals) and \n",
    "    x != 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['due_date',\n",
       " 'first_status_day_date',\n",
       " 'first_status_time_of_day',\n",
       " 'paid_date',\n",
       " 'arrived_date',\n",
       " 'Variable_42',\n",
       " 'Variable_43',\n",
       " 'Variable_44']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_13</th>\n",
       "      <th>Variable_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>RATINGSTUFE M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>RATINGSTUFE M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>RATINGSTUFE G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>RATINGSTUFE D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K</td>\n",
       "      <td>RATINGSTUFE K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>RATINGSTUFE G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I</td>\n",
       "      <td>RATINGSTUFE I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>RATINGSTUFE F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>RATINGSTUFE M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable_13    Variable_14\n",
       "0           M  RATINGSTUFE M\n",
       "1           M  RATINGSTUFE M\n",
       "2           G  RATINGSTUFE G\n",
       "3           D  RATINGSTUFE D\n",
       "4         NaN            NaN\n",
       "5           K  RATINGSTUFE K\n",
       "6           G  RATINGSTUFE G\n",
       "7           I  RATINGSTUFE I\n",
       "8           F  RATINGSTUFE F\n",
       "9           M  RATINGSTUFE M"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Variable_13','Variable_14']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripper(value):\n",
    "    value = str(value).split()\n",
    "    if len(value)>1:\n",
    "        return value[1]\n",
    "    elif value[0]=='nan':\n",
    "        return pd.np.nan\n",
    "    else:\n",
    "        print('error')\n",
    "test = data['Variable_14'].apply(stripper , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n",
      "(0, 2)\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data[(data.Variable_13 != test) & (data.Variable_13.notnull()) & (test.notnull())] [['Variable_13','Variable_14']].shape)\n",
    "print(data[(data.Variable_13 != test) & (test.notnull())] [['Variable_13','Variable_14']].shape)\n",
    "print(data[(data.Variable_13 != test) & (data.Variable_13.notnull())] [['Variable_13','Variable_14']].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Variable 14 and move this analysis in notebook one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical and Ordinals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_categorical(dataset, columns_to_transform):\n",
    "    \"\"\"Translates categorical columns into integers.\"\"\"\n",
    "\n",
    "    categorical_dictionary = {}\n",
    "    for column in columns_to_transform:\n",
    "        categories = pd.Categorical(dataset[column])\n",
    "        new_column = '{prefix}{suffix}'.format(prefix=column, suffix='_INT')\n",
    "        dataset.loc[:, new_column] = categories.codes\n",
    "        categorical_dictionary[column] = dict([(k, v) for v, k in enumerate(categories.categories)])\n",
    "        \n",
    "    return dataset, categorical_dictionary\n",
    "\n",
    "def transform_ordinals(dataset, columns_to_transform, mapper):\n",
    "    \"\"\"Translates categorical columns into integers.\"\"\"\n",
    "\n",
    "    categorical_dictionary = {}\n",
    "    for column in columns_to_transform:\n",
    "        new_column = '{prefix}{suffix}'.format(prefix=column, suffix='_INT')\n",
    "        dataset.loc[:, new_column] = dataset[column].map(mapper[column])\n",
    "    return dataset\n",
    "\n",
    "ordinal_dictionary ={\n",
    "    'Variable_13': {\n",
    "        'A': 0,\n",
    "        'B': 1,\n",
    "        'C': 2,\n",
    "        'D': 3,\n",
    "        'E': 4,\n",
    "        'F': 5,\n",
    "        'G': 6,\n",
    "        'H': 7,\n",
    "        'I': 8,\n",
    "        'J': 9, # Added manually\n",
    "        'K': 10,\n",
    "        'L': 11,\n",
    "        'M': 12},\n",
    "        \n",
    "    'Variable_14': {\n",
    "        'RATINGSTUFE A': 0,\n",
    "        'RATINGSTUFE B': 1,\n",
    "        'RATINGSTUFE C': 2,\n",
    "        'RATINGSTUFE D': 3,\n",
    "        'RATINGSTUFE E': 4,\n",
    "        'RATINGSTUFE F': 5,\n",
    "        'RATINGSTUFE G': 6,\n",
    "        'RATINGSTUFE H': 7,\n",
    "        'RATINGSTUFE I': 8,\n",
    "        'RATINGSTUFE J': 8, # Addedd manually\n",
    "        'RATINGSTUFE K': 9,\n",
    "        'RATINGSTUFE L': 10,\n",
    "        'RATINGSTUFE M': 11}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard outiers\n",
    "data = data[data.Variable_45 !='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, categorical_dictionary = transform_categorical(data, categoricals)\n",
    "data =  transform_ordinals(data, ordinals, ordinal_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 61)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_dictionary = pickle.dump(categorical_dictionary, open('data/categorical_dictionary.pkl','wb'))\n",
    "ordinal_dictionary = pickle.dump(categorical_dictionary, open('data/ordinal_dictionary.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in dates:\n",
    "    data[date] = pd.to_datetime(data[date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dates_day(dataset, columns_to_transform):\n",
    "    \"\"\"Translates dates columns into integers. Granularity: Year, Month, Day\"\"\"\n",
    "    \n",
    "    for column in columns_to_transform:\n",
    "        new_column_year = '{prefix}{suffix}'.format(prefix=column, suffix='_YEAR')\n",
    "        new_column_month = '{prefix}{suffix}'.format(prefix=column, suffix='_MONTH')\n",
    "        new_column_day = '{prefix}{suffix}'.format(prefix=column, suffix='_DAY')\n",
    "        \n",
    "        dataset.loc[:, new_column_year] = dataset.loc[:, column].dt.year\n",
    "        dataset.loc[:, new_column_month] = dataset.loc[:, column].dt.month\n",
    "        dataset.loc[:, new_column_day] = dataset.loc[:, column].dt.day\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dates_second(dataset, columns_to_transform):\n",
    "    \"\"\"Translates dates columns into integers. Granularity: Hour, Minute, Second\"\"\"\n",
    "    \n",
    "    for column in columns_to_transform:\n",
    "        new_column_hour = '{prefix}{suffix}'.format(prefix=column, suffix='_HOUR')\n",
    "        new_column_minute = '{prefix}{suffix}'.format(prefix=column, suffix='_MINUTE')\n",
    "        new_column_second = '{prefix}{suffix}'.format(prefix=column, suffix='_SECOND')\n",
    "        \n",
    "        dataset.loc[:, new_column_hour] = dataset.loc[:, column].dt.hour\n",
    "        dataset.loc[:, new_column_minute] = dataset.loc[:, column].dt.minute\n",
    "        dataset.loc[:, new_column_second] = dataset.loc[:, column].dt.second\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = transform_dates_day(data, ['due_date','first_status_day_date','paid_date','arrived_date','Variable_42','Variable_43','Variable_44'])\n",
    "data = transform_dates_second(data, ['first_status_time_of_day','arrived_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 88)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Adding distance between dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for couple in combinations(['due_date','first_status_day_date','paid_date','arrived_date','Variable_42','Variable_43','Variable_44'],2):\n",
    "    columnn_name = \"DAYS_{}-{}\".format(couple[0],couple[1])\n",
    "    days = (data[couple[0]] - data[couple[1]]).dt.days\n",
    "    data[columnn_name] = days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 109)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: Adding ratios of couples of numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for couple in combinations(numericals,2):\n",
    "    columnn_name = \"RATIO_{}-{}\".format(couple[0],couple[1])\n",
    "    ratio = (data[couple[0]].divide(data[couple[1]]))\n",
    "    data[columnn_name] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 109)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Transformed Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(categoricals, axis=1)\n",
    "data = data.drop(ordinals, axis=1)\n",
    "data = data.drop(dates, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Constant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_constant_column(dataframe):\n",
    "    \"\"\"Drops constant value columns of pandas dataframe.\"\"\"\n",
    "    \n",
    "    return dataframe.loc[:, (dataframe != dataframe.iloc[0]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = drop_constant_column(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 90)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_id\n",
      "customer_id\n"
     ]
    }
   ],
   "source": [
    "for c in data.columns:\n",
    "    if c in ids:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Empty Columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_columns_to_drop = []\n",
    "empty_threshold_to_be_dropped = 90\n",
    "for column in [x for x in data.columns if x != 'Target']:\n",
    "    emptyness = float(data[column].isnull().sum() * 100) /data.shape[0]\n",
    "    if emptyness >= empty_threshold_to_be_dropped:\n",
    "        empty_columns_to_drop.append(column)\n",
    "        \n",
    "data = data.drop(empty_columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 24 columns\n"
     ]
    }
   ],
   "source": [
    "print('Dropping {} columns'.format(len(empty_columns_to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 66)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save datasets before inputing NaN for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = data[data.Target.notnull()]\n",
    "target = temp_data['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    temp_data.drop(['Target'], 1),\n",
    "    target, \n",
    "    test_size=0.25, \n",
    "    random_state=2019,\n",
    "    stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('data/preprocessed_entire_set.csv', sep=';', index=False)\n",
    "#target.to_csv('data/entire_target.csv', sep=';', index=False, header='Target')\n",
    "\n",
    "X_train.to_csv('data/preprocessed_train_set_NAN.csv', sep=';', index=False)\n",
    "y_train.to_csv('data/train_target_NAN.csv', sep=';', index=False, header='Target')\n",
    "\n",
    "X_test.to_csv('data/preprocessed_test_set_NAN.csv', sep=';', index=False)\n",
    "y_test.to_csv('data/test_target_NAN.csv', sep=';', index=False,  header='Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Emptyness Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Variable_21</th>\n",
       "      <td>1985</td>\n",
       "      <td>0.773879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_38</th>\n",
       "      <td>1985</td>\n",
       "      <td>0.773879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_22</th>\n",
       "      <td>1754</td>\n",
       "      <td>0.683821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_39</th>\n",
       "      <td>1754</td>\n",
       "      <td>0.683821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_37</th>\n",
       "      <td>1099</td>\n",
       "      <td>0.428460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_20</th>\n",
       "      <td>1099</td>\n",
       "      <td>0.428460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>515</td>\n",
       "      <td>0.200780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_26</th>\n",
       "      <td>184</td>\n",
       "      <td>0.071735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_27</th>\n",
       "      <td>184</td>\n",
       "      <td>0.071735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable_28</th>\n",
       "      <td>184</td>\n",
       "      <td>0.071735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  Emptyness Percentage\n",
       "Variable_21   1985              0.773879\n",
       "Variable_38   1985              0.773879\n",
       "Variable_22   1754              0.683821\n",
       "Variable_39   1754              0.683821\n",
       "Variable_37   1099              0.428460\n",
       "Variable_20   1099              0.428460\n",
       "Target         515              0.200780\n",
       "Variable_26    184              0.071735\n",
       "Variable_27    184              0.071735\n",
       "Variable_28    184              0.071735"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Emptyness Percentage'])\n",
    "missing_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [x for x in data.columns if x != 'Target']:\n",
    "    data[column] = data[column].replace([np.inf, -np.inf], np.nan)\n",
    "    data[column] = data[column].fillna((data[column].mean()))\n",
    "    #data[column] = data[column].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 66)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temp_target = data['Target']\n",
    "\n",
    "data.drop(['Target'], 1, inplace=True)\n",
    "temp_A = pd.DataFrame(data[[x for x in ids if x in data.columns]])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "temp_B = min_max_scaler.fit_transform(data[[x for x in data.columns if x not in ids]])\n",
    "temp_B = pd.DataFrame(temp_B, columns=[x for x in data.columns if x not in ids])\n",
    "\n",
    "data = pd.concat([temp_A, temp_B, temp_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2565, 66)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Ferratum Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferratum_preprocessed_test_set = data[data.Target.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 66)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ferratum_preprocessed_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferratum_preprocessed_test_set.to_csv('data/ferratum_preprocessed_test_set.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.Target.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Undersampling\n",
    "print(data[data.Target ==1].shape)\n",
    "print(data[data.Target ==0].shape)\n",
    "new_data = data[data.Target ==1].sample(633)\n",
    "new_data = new_data.append(data[data.Target ==0])\n",
    "data = new_data.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U --user git+https://github.com/scikit-learn-contrib/imbalanced-learn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Target'], 1 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2050, 65)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-fb4e10e1e7b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### Oversampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBorderlineSMOTE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVMSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVMSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtemp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "##### Oversampling\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE \n",
    "sm = SVMSMOTE(random_state=2019, k_neighbors=10)\n",
    "temp_data, temp_target = sm.fit_resample(data, target)\n",
    "data = pd.DataFrame(temp_data, columns=data.columns)\n",
    "target = pd.DataFrame(temp_target, columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2050, 65)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, \n",
    "    target, \n",
    "    test_size=0.25, \n",
    "    random_state=2019,\n",
    "    stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2136, 65)\n",
      "(2136, 1)\n",
      "(712, 65)\n",
      "(712, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/preprocessed_entire_set.csv', sep=';', index=False)\n",
    "target.to_csv('data/entire_target.csv', sep=';', index=False, header='Target')\n",
    "\n",
    "X_train.to_csv('data/preprocessed_train_set.csv', sep=';', index=False)\n",
    "y_train.to_csv('data/train_target.csv', sep=';', index=False, header='Target')\n",
    "\n",
    "X_test.to_csv('data/preprocessed_test_set.csv', sep=';', index=False)\n",
    "y_test.to_csv('data/test_target.csv', sep=';', index=False,  header='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
